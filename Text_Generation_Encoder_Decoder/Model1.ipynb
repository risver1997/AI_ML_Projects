{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ae96bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import os, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ecd4ef7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import StringLookup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2fe05e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.6.0'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "875e5ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_file = keras.utils.get_file(\"shakespeare.txt\", \"https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1af13e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the text is 1115394 characters long\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it be done: away, away!\n",
      "\n",
      "Second Citizen:\n",
      "One word, good citizens.\n",
      "\n",
      "First Citizen:\n",
      "We are accounted poor citizens, the patricians good.\n",
      "What authority surfeits on would relieve us: if they\n",
      "would yield us but the superfluity, while it were\n",
      "wholesome, we might guess they relieved us humanely;\n",
      "but they think we are too dear: the leanness that\n",
      "afflicts us, the object of our misery, is as an\n",
      "inventory to particularise their abundance; our\n",
      "sufferance is a gain to them Let us revenge this with\n",
      "our pikes, ere we become rakes: for the gods know I\n",
      "speak this in hunger for bread, not in thirst for revenge.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text = open(path_to_file, \"rb\").read().decode(encoding=\"utf-8\")\n",
    "print(f\"the text is {len(text)} characters long\")\n",
    "print(text[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45188052",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65 unique characters\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(text))\n",
    "print(f\"{len(vocab)} unique characters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e021f722",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Todo 2\n",
    "example_texts = [\"abcdefg\", \"xyz\"]\n",
    "\n",
    "chars = tf.strings.unicode_split(example_texts, input_encoding=\"UTF-8\")\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f24d7f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_from_chars = StringLookup(\n",
    "    vocabulary=list(vocab), mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7f2017bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = ids_from_chars(chars)\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3933501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_from_ids = StringLookup(\n",
    "    vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "73a34b49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = chars_from_ids(ids)\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c398face",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([b'abcdefg', b'xyz'], dtype=object)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.strings.reduce_join(chars, axis=-1).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e2ca055",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_from_ids(ids):\n",
    "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "907bd75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1], dtype=int64)>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Todo 3\n",
    "all_ids = ids_from_chars(tf.strings.unicode_split(text, \"UTF-8\"))\n",
    "all_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fc3d7dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "da04ec99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F\n",
      "i\n",
      "r\n",
      "s\n",
      "t\n",
      " \n",
      "C\n",
      "i\n",
      "t\n",
      "i\n"
     ]
    }
   ],
   "source": [
    "for ids in ids_dataset.take(10):\n",
    "    print(chars_from_ids(ids).numpy().decode(\"utf-8\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5d1104e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_length = 100\n",
    "examples_per_epoch = len(text) // (seq_length + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "131536e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
      " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
      " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
      " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
      " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
      " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
      " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
      " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
    "for seq in sequences.take(1):\n",
    "    print(chars_from_ids(seq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a4bb167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
      "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
      "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
      "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
      "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
     ]
    }
   ],
   "source": [
    "for seq in sequences.take(5):\n",
    "    print(text_from_ids(seq).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d84682d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_target(sequence):\n",
    "    input_text = sequence[:-1]\n",
    "    target_text = sequence[1:]\n",
    "    return input_text, target_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "245c4330",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Tensorflo', 'ensorflow')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_input_target(\"Tensorflow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "13caacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = sequences.map(split_input_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6fbc121",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input example:  b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
      "Output_example:  b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
     ]
    }
   ],
   "source": [
    "for input_example, output_example in dataset.take(1):\n",
    "    print(\"Input example: \", text_from_ids(input_example).numpy())\n",
    "    print(\"Output_example: \", text_from_ids(output_example).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19ec7c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((64, 100), (64, 100)), types: (tf.int64, tf.int64)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 64\n",
    "BUFFER_SIZE = 10000\n",
    "\n",
    "dataset = (dataset.shuffle(BUFFER_SIZE)\n",
    "          .batch(BATCH_SIZE, drop_remainder=True)\n",
    "          .prefetch(tf.data.experimental.AUTOTUNE))\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0b7acb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size=len(vocab)\n",
    "embedding_dim = 256\n",
    "rnn_units = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf05fa32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
    "        super().__init__(self)\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = tf.keras.layers.GRU(rnn_units, return_sequences=True, return_state=True)\n",
    "        self.dense = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "    def call(self, inputs, states=None, return_state=False, training=False):\n",
    "        x = self.embedding(inputs, training=training)\n",
    "        \n",
    "        if states is None:\n",
    "            states = self.gru.get_initial_state(x)\n",
    "        x, states = self.gru(x, initial_state = states, training=training)\n",
    "        x = self.dense(x, training=training)\n",
    "        \n",
    "        if return_state:\n",
    "            return x, states\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ae266aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=MyModel(vocab_size = len(ids_from_chars.get_vocabulary()),\n",
    "              embedding_dim = embedding_dim,\n",
    "              rnn_units = rnn_units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "38fb0d46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64, 100, 66) # batch_size, sequence_length, vocab_size\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, output_example_batch in dataset.take(1):\n",
    "    example_batch_predictions = model(input_example_batch)\n",
    "    print(example_batch_predictions.shape,\n",
    "          \"# batch_size, sequence_length, vocab_size\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "df509d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"my_model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  16896     \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    multiple                  3938304   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  67650     \n",
      "=================================================================\n",
      "Total params: 4,022,850\n",
      "Trainable params: 4,022,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "afa167b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([15, 61,  9, 44,  7, 29, 59,  5,  1, 22, 12, 22, 30, 18, 60, 49, 34,\n",
       "       28, 17, 31, 63, 64, 13, 43, 18, 59, 18, 57, 42, 35, 38, 31,  9, 41,\n",
       "       60, 63, 50,  8, 62, 49, 52,  8, 49, 33, 42, 12,  8,  9, 27, 23, 45,\n",
       "       62, 35, 31, 11, 37, 26, 65, 18, 31, 40, 42, 38, 40, 43,  7,  7, 30,\n",
       "       16, 57, 30, 35, 64, 58, 65,  3, 11,  1, 32, 15, 16, 57, 13, 60, 34,\n",
       "        1, 53, 44, 36, 44, 21, 10, 49, 26,  5, 15, 29, 31, 19,  1],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
    "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()\n",
    "sampled_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "18703159",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: \n",
      " b\"orshipp'd sun\\nPeer'd forth the golden window of the east,\\nA troubled mind drave me to walk abroad;\\nW\"\n",
      "\n",
      "Next char predictions: \n",
      " b'Bv.e,Pt&\\nI;IQEujUODRxy?dEtErcVYR.buxk-wjm-jTc;-.NJfwVR:XMzERacYad,,QCrQVysz!:\\nSBCr?uU\\nneWeH3jM&BPRF\\n'\n"
     ]
    }
   ],
   "source": [
    "print(\"Input: \\n\", text_from_ids(input_example_batch[0]).numpy())\n",
    "print()\n",
    "print(\"Next char predictions: \\n\", text_from_ids(sampled_indices).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0297e171",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6240deed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
      "Mean Loss:  tf.Tensor(4.1899133, shape=(), dtype=float32)\n",
      "66.01707\n"
     ]
    }
   ],
   "source": [
    "for input_example_batch, target_example_batch in dataset.take(1):\n",
    "    example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
    "    print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
    "    print(\"Mean Loss: \", example_batch_mean_loss)\n",
    "    print(tf.exp(example_batch_mean_loss).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b1198996",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss = loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "57f3a139",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"./training_checkpoints\"\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "                      filepath=checkpoint_prefix, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "beb7c681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "172/172 [==============================] - 5s 17ms/step - loss: 2.7302\n",
      "Epoch 2/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 1.9969\n",
      "Epoch 3/10\n",
      "172/172 [==============================] - 4s 17ms/step - loss: 1.7144\n",
      "Epoch 4/10\n",
      "172/172 [==============================] - 4s 17ms/step - loss: 1.5521\n",
      "Epoch 5/10\n",
      "172/172 [==============================] - 4s 17ms/step - loss: 1.4527\n",
      "Epoch 6/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 1.3844\n",
      "Epoch 7/10\n",
      "172/172 [==============================] - 3s 17ms/step - loss: 1.3310\n",
      "Epoch 8/10\n",
      "172/172 [==============================] - 4s 17ms/step - loss: 1.2846\n",
      "Epoch 9/10\n",
      "172/172 [==============================] - 4s 17ms/step - loss: 1.2437\n",
      "Epoch 10/10\n",
      "172/172 [==============================] - 4s 17ms/step - loss: 1.2049\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(dataset, epochs=10, callbacks = [checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b67d2521",
   "metadata": {},
   "outputs": [],
   "source": [
    "class OneStep(tf.keras.Model):\n",
    "    def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        self.model = model\n",
    "        self.chars_from_ids = chars_from_ids\n",
    "        self.ids_from_chars = ids_from_chars\n",
    "        \n",
    "        skip_ids = self.ids_from_chars([\"[UNK]\"])[:, None]\n",
    "        sparse_mask = tf.SparseTensor(\n",
    "                        values = [-float(\"inf\")]*len(skip_ids),\n",
    "                        indices = skip_ids,\n",
    "                        dense_shape = [len(ids_from_chars.get_vocabulary())],)\n",
    "        self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
    "\n",
    "    @tf.function\n",
    "    def generate_one_step(self, inputs, states=None):\n",
    "        input_chars = tf.strings.unicode_split(inputs, \"UTF-8\")\n",
    "        input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
    "        \n",
    "        predicted_logits, states = self.model(inputs = input_ids, states = states, return_state=True)\n",
    "        predicted_logits = predicted_logits[:, -1, :]\n",
    "        predicted_logits = predicted_logits / self.temperature\n",
    "        predicted_logits = predicted_logits + self.prediction_mask\n",
    "        \n",
    "        predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
    "        predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
    "        \n",
    "        predicted_chars = self.chars_from_ids(predicted_ids)\n",
    "        \n",
    "        return predicted_chars, states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3ceac552",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_model = OneStep(model, chars_from_ids, ids_from_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1a771a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "It is spite your wrockly, till they're?\n",
      "\n",
      "GRUMIO:\n",
      "Fell so: yea, leanness sibtle pardon.\n",
      "\n",
      "SICINIUS:\n",
      "What, host madeage?\n",
      "\n",
      "ANGELO:\n",
      "My lord.\n",
      "\n",
      "GREMIO:\n",
      "O gallable!\n",
      "How sir, I do be so, by thee?\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Come all do: for it shall not have it, to receive from the glother's faith.\n",
      "But say, say 'em!' That's your quarrel: till I'll tell her ignoran,\n",
      "And he my grace geneward hanting: but if a\n",
      "Dow from sline of weathing her young pride.\n",
      "\n",
      "TENTIIO:\n",
      "Not at that kingled father, and faults,\n",
      "Exam to you.\n",
      "\n",
      "LUCIO:\n",
      "Why, none than any world to brawn Claudio?\n",
      "\n",
      "MARCIUS:\n",
      "Ne'er trust to be into myself.\n",
      "\n",
      "HORTENSIO:\n",
      "Condend thee, with all but strength in meth,\n",
      "If brother having for me in headness,\n",
      "As be us to our pretry floxe.\n",
      "\n",
      "FRIAR LAURENCE:\n",
      "\n",
      "PAULINA:\n",
      "Nay, tut,\n",
      "And all thy brother He mistands from\n",
      "sings at me, were they go about this beauteful friend\n",
      "Hath spoken fair and tale them king,\n",
      "May not remained eyes but life look.\n",
      "My father gave him baw thy choice nor inkeen.\n",
      "And when I love the likelict see,\n",
      "An \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time:  2.1300010681152344\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant([\"ROMEO:\"])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode(\"utf-8\"), \"\\n\\n\" + \"_\" * 80)\n",
    "print(\"\\nRun time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8eb2f410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "Even what morions will have found you try death?\n",
      "Here's it friends in the noble duke ert report.\n",
      "\n",
      "GREMIO:\n",
      "And you in Tutnot will, my lord.\n",
      "\n",
      "VILINIUS:\n",
      "If, therefore from thy banish is't\n",
      "for your true dead days levy.\n",
      "\n",
      "SLY:\n",
      "'Tis like all for I would have look'st envion against\n",
      "The world is breath; and then it say that which he request,\n",
      "As east will sleep not in the city feed;\n",
      "But I'll want the best,\n",
      "To strike up your rabs, the oracle-forced thee for,\n",
      "My receives which he ishined in the bea.\n",
      "But Henry of his warding broken\n",
      "Those fear of mine eyes to me for't:\n",
      "I chy point thou be content;\n",
      "And strock and scorns the king's death, alive,\n",
      "Out of a grave with all prace eyes with words:\n",
      "And so I think, no man common buy.\n",
      "Farewell.\n",
      "\n",
      "GLOUCESTER:\n",
      "Neaven, I'll tribund to o'er the perit;\n",
      "And thrive my violan of the fearful lamfs,\n",
      "God growing by the garland of Menenity'\n",
      "Was he will prevails not that you but weth.\n",
      "Nay think my poor from tain'd Clifford,\n",
      "Which thy arguous thursdary: let our rascell\n",
      "As t \n",
      "\n",
      "________________________________________________________________________________\n",
      "\n",
      "Run time:  1.656996726989746\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "states = None\n",
    "next_char = tf.constant([\"ROMEO:\", \"ROMEO:\", \"ROMEO:\", \"ROMEO:\", \"ROMEO:\"])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_model.generate_one_step(next_char, states=states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "end = time.time()\n",
    "print(result[0].numpy().decode(\"utf-8\"), \"\\n\\n\" + \"_\" * 80)\n",
    "print(\"\\nRun time: \", end-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fcc2fa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x0000014CA903ED60>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_fn, gru_cell_layer_call_and_return_conditional_losses, gru_cell_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: one_step\\assets\n"
     ]
    }
   ],
   "source": [
    "tf.saved_model.save(one_step_model, \"one_step\")\n",
    "one_step_reloaded = tf.saved_model.load(\"one_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b02558ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROMEO:\n",
      "Nay, with all persuading friends,\n",
      "Your willingly as art by right,\n",
      "Good morrily; for thy thy chose them further night\n",
      "Shall lose his brother; and my frozen content.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "It is the adverse ballads that I had pund\n",
      "But for this trual friends your voices.\n",
      "\n",
      "YORK:\n",
      "If any lady courses and death will pit it is;\n",
      "And yet I'll pitiful army: therefore, by a fale,\n",
      "since his woefully, take it not,\n",
      "That think changes will appeal me claip or his firm\n",
      "As is he and an hurters cock,\n",
      "This triughts traitor is no less will; but no,\n",
      "Though I am continent again.\n",
      "\n",
      "JOHN OF GAUNT:\n",
      "Well, I may not done: this gracious Lord of God, thou hast\n",
      "A fool thy words a vallad fount beward of man.\n",
      "Dest I proceed, and for are gold with the nobles,\n",
      "Sometimes they erw commatuness. Being masters,\n",
      "I crave forth fear that shrift arms enemy nay, when I have\n",
      "Ert remomest an arry too.\n",
      "\n",
      "BRUTUS:\n",
      "I do court to prison; this world's; and\n",
      "Shall'st thou reely sent this busicu.\n",
      "\n",
      "ELBOW:\n",
      "Fie frumble times against this world.\n",
      "\n",
      "Byow \n"
     ]
    }
   ],
   "source": [
    "states = None\n",
    "next_char = tf.constant([\"ROMEO:\"])\n",
    "result = [next_char]\n",
    "\n",
    "for n in range(1000):\n",
    "    next_char, states = one_step_reloaded.generate_one_step(next_char, states)\n",
    "    result.append(next_char)\n",
    "\n",
    "result = tf.strings.join(result)\n",
    "print(result[0].numpy().decode(\"utf-8\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "machine_learning",
   "language": "python",
   "name": "machine_learning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
